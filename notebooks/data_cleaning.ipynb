{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Cleans raw public data to produce the following two files:\n",
    "\n",
    "1. '../data/crosscheck_daily_data_cleaned_w_sameday.csv'\n",
    "2. '../data/studentlife_daily_data_cleaned_w_sameday_03192020.csv'\n",
    "\n",
    "The original raw datasets will need to be downloaded from the following links to use this code:\n",
    "\n",
    "* Download the \"CrossCheck_Daily_Data.csv\" from https://cornell.box.com/s/rkx46bgv36lkmo2eu349ka95senn48gh\n",
    "* Download the raw StudentLife data and unzip from https://studentlife.cs.dartmouth.edu/dataset.html\n",
    "\n",
    "The code below will guide you to place the paths to each of the downloaded files in a variable.\n",
    "\n",
    "Requires the following code files in the repo:\n",
    "\n",
    "1. '../src/util.py'\n",
    "2. '.../src/cleaning_util.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import local code files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import cleaning_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossCheck Daily Data Feature Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the \"CrossCheck_Daily_Data.csv\" from https://cornell.box.com/s/rkx46bgv36lkmo2eu349ka95senn48gh\n",
    "# fill in local path in variable below\n",
    "crosscheck_daily_data_path = ''\n",
    "daily_data = pd.read_csv(crosscheck_daily_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preppinng\n",
    "daily_data['date'] = pd.to_datetime(daily_data['day'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get potential features\n",
    "feature_cols = [f for f in daily_data.columns.values if f not in ['study_id', 'eureka_id', 'day', 'date']]\n",
    "ema_cols = [f for f in feature_cols if 'ema' in f]\n",
    "behavior_cols = [f for f in feature_cols if 'ema' not in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaging over 1-3 days for each feature. Same as:\n",
    "\n",
    "[1] Rui Wang, Emily A. Scherer, Vincent W. S. Tseng, et al. 2016. CrossCheck: toward passive sensing and detection of mental health changes in people with schizophrenia. Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing - UbiComp ’16, ACM Press, 886–897."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort\n",
    "daily_data = daily_data.sort_values(['study_id', 'date']).reset_index(drop=True)\n",
    "# Copy over EMA columns\n",
    "crosscheck_df = daily_data[['study_id', 'eureka_id', 'date'] + ema_cols].copy()\n",
    "for f in behavior_cols:\n",
    "    crosscheck_df[f] = None\n",
    "# Add a column to collect missing days of data\n",
    "crosscheck_df['missing_days'] = 0\n",
    "\n",
    "# Go through each study ID\n",
    "curr = 0\n",
    "for s in daily_data.study_id.unique():\n",
    "    if (curr % 1) == 0:\n",
    "        print(curr)\n",
    "    # Go through each EMA date, discarding the first EMA taken\n",
    "    for ind in daily_data.loc[\n",
    "        (daily_data.study_id == s) & (pd.isnull(daily_data[ema_cols]).sum(axis=1) == 0), :].index[1:]:\n",
    "        # Get date\n",
    "        d = daily_data.loc[ind, 'date']\n",
    "        # Now see if data exists in other df\n",
    "        start_date = d - timedelta(days=2)\n",
    "        end_date = d\n",
    "        filtered_df = daily_data.loc[\n",
    "            (daily_data.study_id == s) & (daily_data.date >= start_date) & (daily_data.date <= end_date), :\n",
    "        ]\n",
    "        if filtered_df.shape[0] > 0:\n",
    "            # Get mean\n",
    "            crosscheck_df.loc[ind, behavior_cols] = filtered_df[behavior_cols].mean().values\n",
    "            # Check for null values across all columns\n",
    "        crosscheck_df.loc[ind, 'missing_days'] = 3 - filtered_df.shape[0]\n",
    "        \n",
    "    curr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rowss where there is not EMA data\n",
    "crosscheck_df_cleaned = crosscheck_df.dropna(subset=ema_cols)\n",
    "# Drop all rows where this is no behavioral data and no missing data was marked\n",
    "# These should be the first EMA\n",
    "crosscheck_df_cleaned = crosscheck_df_cleaned.loc[~(\n",
    "        (pd.isnull(crosscheck_df_cleaned[behavior_cols]).sum(axis=1) == len(behavior_cols)) & \\\n",
    "        (crosscheck_df_cleaned.missing_days < 3)\n",
    "    ), :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosscheck_df_cleaned.to_csv('../data/crosscheck_daily_data_cleaned_w_sameday.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StudentLife Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the raw StudentLife data from: https://studentlife.cs.dartmouth.edu/dataset.html\n",
    "# Unzip the file, and put the path to the unzipped file in the variable below\n",
    "\n",
    "studentlife_unzipped = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMA File Prep\n",
    "\n",
    "#### Upload EMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_social_files = util.upload_directory(\n",
    "    studentlife_unzipped + '/dataset/EMA/response/Social/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_stress_files = util.upload_directory(\n",
    "    studentlife_unzipped + '/dataset/EMA/response/Stress/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_sleep_files = util.upload_directory(\n",
    "    studentlife_unzipped + '/dataset/EMA/response/Sleep/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_behavior_files = util.upload_directory(\n",
    "    studentlife_unzipped + '/dataset/EMA/response/Behavior/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_mood_files = util.upload_directory(\n",
    "    studentlife_unzipped + '/dataset/EMA/response/Mood/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_pam_files = util.upload_directory(\n",
    "    studentlife_unzipped + '/dataset/EMA/response/PAM/',\n",
    "    file_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep EMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dfs from EMA data\n",
    "ema_mood_df = cleaning_util.prep_studentlife_df(ema_mood_files)\n",
    "ema_social_df = cleaning_util.prep_studentlife_df(ema_social_files)\n",
    "ema_stress_df = cleaning_util.prep_studentlife_df(ema_stress_files)\n",
    "ema_sleep_df = cleaning_util.prep_studentlife_df(ema_sleep_files)\n",
    "ema_behavior_df = cleaning_util.prep_studentlife_df(ema_behavior_files)\n",
    "ema_pam_df = cleaning_util.prep_studentlife_df(ema_pam_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "studentlife_ema_df = cleaning_util.prep_ema_data(\n",
    "    [ema_mood_df, ema_social_df, ema_stress_df, ema_sleep_df, ema_behavior_df, ema_pam_df]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Data Prep\n",
    "\n",
    "#### Upload sensor data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activity_files = util.upload_directory(studentlife_unzipped + '/dataset/sensing/activity/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_files = util.upload_directory_from_magma(studentlife_unzipped + '/dataset/sensing/conversation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_files = util.upload_directory_from_magma(studentlife_unzipped + '/dataset/sensing/gps/', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_lock_files = util.upload_directory_from_magma(studentlife_unzipped + '/dataset/sensing/phonelock/', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_files = util.upload_directory_from_magma(studentlife_unzipped + '/dataset/sensing/dark/', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = util.upload_directory_from_magma(studentlife_unzipped + '/dataset/sensing/audio/', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_charge_files = util.upload_directory_from_magma(studentlife_unzipped + '/dataset/sensing/phonecharge/', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep Sensor Data\n",
    "\n",
    "##### Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activity_df = cleaning_util.clean_studentlife_activity(activity_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_df = cleaning_util.clean_studentlife_conversations(conversation_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phone unlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlock_df = cleaning_util.clean_studentlife_unlock(phone_lock_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPS location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_df = cleaning_util.clean_studentlife_location(gps_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df = cleaning_util.clean_sleep_data(\n",
    "    phone_lock_files, cutoff_duration=15, start_time=23, ema_df=studentlife_ema_df,\n",
    "    correction='median'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter to days with >= 19 hours of day\n",
    "\n",
    "Same procedure used in CrossCheck data cleaning:\n",
    "\n",
    "[1] Rui Wang, Emily A. Scherer, Vincent W. S. Tseng, et al. 2016. CrossCheck: toward passive sensing and detection of mental health changes in people with schizophrenia. Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing - UbiComp ’16, ACM Press, 886–897."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_days = cleaning_util.get_good_days(dfs=activity_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Cleaned StudentLife Data\n",
    "\n",
    "Note: We are only merging the feature files that align and were used in prediction analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [studentlife_ema_df, activity_df, conversation_df, gps_df, sleep_df]\n",
    "\n",
    "merged_df = good_days[['study_id', 'day']].copy()\n",
    "for df in dfs:\n",
    "    if merged_df is None:\n",
    "        merged_df = df.copy()\n",
    "    else:\n",
    "        merged_df = pd.merge(left=merged_df, right=df, on=['study_id', 'day'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StudentLife prep for prediction\n",
    "\n",
    "Averaging over 1-3 days for each feature. Same as:\n",
    "\n",
    "[1] Rui Wang, Emily A. Scherer, Vincent W. S. Tseng, et al. 2016. CrossCheck: toward passive sensing and detection of mental health changes in people with schizophrenia. Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing - UbiComp ’16, ACM Press, 886–897."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_daily_df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_daily_df['day'] = pd.to_datetime(sl_daily_df['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get potential features\n",
    "sl_feature_cols = [f for f in sl_daily_df.columns.values if f not in ['study_id', 'day']]\n",
    "sl_ema_cols = [f for f in sl_feature_cols if 'ema' in f]\n",
    "sl_behavior_cols = [f for f in sl_feature_cols if 'ema' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort\n",
    "sl_daily_df = sl_daily_df.sort_values(['study_id', 'day']).reset_index(drop=True)\n",
    "# Copy over EMA columns\n",
    "sl_df = sl_daily_df[['study_id', 'day'] + sl_ema_cols].copy()\n",
    "for f in sl_behavior_cols:\n",
    "    sl_df[f] = None\n",
    "# Add a column to collect missing days of data\n",
    "sl_df['missing_days'] = 0\n",
    "\n",
    "# Go through each study ID\n",
    "curr = 0\n",
    "\n",
    "keep_index = []\n",
    "\n",
    "for s in sl_daily_df.study_id.unique():\n",
    "    if (curr % 1) == 0:\n",
    "        print(curr)\n",
    "    # Go through each EMA date, discarding the first EMA taken\n",
    "    for ind in sl_daily_df.loc[\n",
    "        (sl_daily_df.study_id == s) &\n",
    "        (((~pd.isnull(sl_daily_df[sl_ema_cols])).sum(axis=1)) > 0), :\n",
    "    ].index[1:]:\n",
    "        # Get date\n",
    "        d = sl_daily_df.loc[ind, 'day']\n",
    "        # Now see if data exists in other df\n",
    "        start_date = d - timedelta(days=2)\n",
    "        end_date = d\n",
    "        filtered_df = sl_daily_df.loc[\n",
    "            (sl_daily_df.study_id == s) & (sl_daily_df.day >= start_date) & \\\n",
    "            (sl_daily_df.day <= end_date), :\n",
    "        ]\n",
    "        if filtered_df.shape[0] > 0:\n",
    "            # Get mean\n",
    "            sl_df.loc[ind, sl_behavior_cols] = filtered_df[sl_behavior_cols].mean().values\n",
    "            # Check for null values across all columns\n",
    "        sl_df.loc[ind, 'missing_days'] = 3 - filtered_df.shape[0]\n",
    "        \n",
    "    curr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows where this is no behavioral data and no missing data was marked\n",
    "sl_df_cleaned = sl_df.copy()\n",
    "# These should be the first EMA\n",
    "sl_df_cleaned = sl_df_cleaned.loc[~(\n",
    "        (pd.isnull(sl_df_cleaned[sl_behavior_cols]).sum(axis=1) == len(sl_behavior_cols)) & \\\n",
    "        (sl_df_cleaned.missing_days < 3)\n",
    "    ), :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_df_cleaned.to_csv('../data/studentlife_daily_data_cleaned_w_sameday_03192020.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
